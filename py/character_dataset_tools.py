#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø¯Ø§ØªØ§ Ø³ÙŠØª Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
Character Dataset Management Tools for Arabic Novels
"""

import json
import csv
from typing import List, Dict, Any
from collections import Counter
import os

class ArabicCharacterDataset:
    """ÙØ¦Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø¯Ø§ØªØ§ Ø³ÙŠØª Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
    
    def __init__(self, file_path: str = None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¯Ø§ØªØ§ Ø³ÙŠØª
        
        Args:
            file_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù JSONL
        """
        self.file_path = file_path
        self.characters = []
        if file_path and os.path.exists(file_path):
            self.load_from_jsonl(file_path)
    
    def load_from_jsonl(self, file_path: str):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ù…Ù† Ù…Ù„Ù JSONL"""
        self.characters = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    self.characters.append(json.loads(line))
        print(f"âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.characters)} Ø´Ø®ØµÙŠØ©")
    
    def save_to_jsonl(self, file_path: str):
        """Ø­ÙØ¸ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù JSONL"""
        with open(file_path, 'w', encoding='utf-8') as f:
            for char in self.characters:
                f.write(json.dumps(char, ensure_ascii=False) + '\n')
        print(f"âœ“ ØªÙ… Ø­ÙØ¸ {len(self.characters)} Ø´Ø®ØµÙŠØ© Ø¥Ù„Ù‰ {file_path}")
    
    def add_character(self, character: Dict[str, Any]):
        """Ø¥Ø¶Ø§ÙØ© Ø´Ø®ØµÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©
        required_fields = ['character_id', 'novel_id', 'name']
        missing = [f for f in required_fields if f not in character]
        
        if missing:
            raise ValueError(f"Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù†Ø§Ù‚ØµØ©: {', '.join(missing)}")
        
        self.characters.append(character)
        print(f"âœ“ ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø´Ø®ØµÙŠØ©: {character['name']}")
    
    def get_character_by_id(self, char_id: str) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´Ø®ØµÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø¹Ø±ÙÙ‡Ø§"""
        for char in self.characters:
            if char.get('character_id') == char_id:
                return char
        return None
    
    def get_characters_by_novel(self, novel_id: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø´Ø®ØµÙŠØ§Øª Ø±ÙˆØ§ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©"""
        return [c for c in self.characters if c.get('novel_id') == novel_id]
    
    def validate(self) -> List[str]:
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ (ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµØ­ÙŠØ­Ø©)
        """
        errors = []
        required_fields = ['character_id', 'novel_id', 'name']
        
        for i, char in enumerate(self.characters, 1):
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©
            missing = [f for f in required_fields if f not in char]
            if missing:
                errors.append(f"Ø§Ù„Ø´Ø®ØµÙŠØ© {i}: Ø­Ù‚ÙˆÙ„ Ù†Ø§Ù‚ØµØ© - {', '.join(missing)}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† character_id ÙØ±ÙŠØ¯
            char_id = char.get('character_id')
            if char_id:
                duplicates = [c for c in self.characters 
                            if c.get('character_id') == char_id]
                if len(duplicates) > 1:
                    errors.append(f"character_id Ù…ÙƒØ±Ø±: {char_id}")
        
        if not errors:
            print("âœ“ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµØ­ÙŠØ­Ø©")
        else:
            print(f"âš  ÙˆÙØ¬Ø¯Øª {len(errors)} Ù…Ø´ÙƒÙ„Ø©")
        
        return errors
    
    def get_statistics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¯Ø§ØªØ§ Ø³ÙŠØª"""
        if not self.characters:
            return {}
        
        stats = {
            'total_characters': len(self.characters),
            'gender_distribution': Counter(c.get('gender', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯') 
                                          for c in self.characters),
            'role_distribution': Counter(c.get('role', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯') 
                                        for c in self.characters),
            'novels_count': len(set(c.get('novel_id') for c in self.characters)),
        }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ù…Ø±
        ages = [c.get('age') for c in self.characters if 'age' in c]
        if ages:
            stats['age_stats'] = {
                'min': min(ages),
                'max': max(ages),
                'average': sum(ages) / len(ages)
            }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù„ØºØ©
        fsa_usages = [c.get('fsa_usage') for c in self.characters 
                     if 'fsa_usage' in c]
        if fsa_usages:
            stats['avg_fsa_usage'] = sum(fsa_usages) / len(fsa_usages)
        
        return stats
    
    def print_statistics(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""
        stats = self.get_statistics()
        
        print("\n" + "="*50)
        print("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¯Ø§ØªØ§ Ø³ÙŠØª Ø§Ù„Ø´Ø®ØµÙŠØ§Øª")
        print("="*50)
        
        print(f"\nğŸ“š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª: {stats.get('total_characters', 0)}")
        print(f"ğŸ“– Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª: {stats.get('novels_count', 0)}")
        
        print("\nğŸ‘¥ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³:")
        for gender, count in stats.get('gender_distribution', {}).items():
            percentage = (count / stats['total_characters']) * 100
            print(f"   {gender}: {count} ({percentage:.1f}%)")
        
        print("\nğŸ­ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Ø±:")
        for role, count in stats.get('role_distribution', {}).items():
            percentage = (count / stats['total_characters']) * 100
            print(f"   {role}: {count} ({percentage:.1f}%)")
        
        if 'age_stats' in stats:
            age_stats = stats['age_stats']
            print("\nğŸ‚ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ù…Ø±:")
            print(f"   Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: {age_stats['min']}")
            print(f"   Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰: {age_stats['max']}")
            print(f"   Ø§Ù„Ù…ØªÙˆØ³Ø·: {age_stats['average']:.1f}")
        
        if 'avg_fsa_usage' in stats:
            fsa_pct = stats['avg_fsa_usage'] * 100
            print(f"\nğŸ“ Ù…ØªÙˆØ³Ø· Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØµØ­Ù‰: {fsa_pct:.1f}%")
        
        print("\n" + "="*50 + "\n")
    
    def export_to_csv(self, file_path: str, fields: List[str] = None):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ CSV
        
        Args:
            file_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù CSV Ø§Ù„Ù†Ø§ØªØ¬
            fields: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø£Ùˆ None Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„)
        """
        if not self.characters:
            print("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´Ø®ØµÙŠØ§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")
            return
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ù‚ÙˆÙ„
        if fields is None:
            # Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
            fields = set()
            for char in self.characters:
                fields.update(char.keys())
            fields = sorted(list(fields))
        
        # ÙƒØªØ§Ø¨Ø© CSV
        with open(file_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fields)
            writer.writeheader()
            
            for char in self.characters:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø¥Ù„Ù‰ Ù†ØµÙˆØµ
                row = {}
                for field in fields:
                    value = char.get(field, '')
                    if isinstance(value, list):
                        value = '|'.join(str(v) for v in value)
                    elif isinstance(value, dict):
                        value = json.dumps(value, ensure_ascii=False)
                    row[field] = value
                writer.writerow(row)
        
        print(f"âœ“ ØªÙ… Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ {file_path}")
    
    def filter_characters(self, **criteria) -> List[Dict[str, Any]]:
        """
        ØªØµÙÙŠØ© Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø¹ÙŠÙ†Ø©
        
        Args:
            **criteria: Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØµÙÙŠØ© (Ù…Ø«Ù„ gender='Ø°ÙƒØ±', role='Ø¨Ø·Ù„')
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        """
        filtered = self.characters
        
        for key, value in criteria.items():
            filtered = [c for c in filtered if c.get(key) == value]
        
        return filtered
    
    def search_by_name(self, name: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø´Ø®ØµÙŠØ© Ø¨Ø§Ù„Ø§Ø³Ù… (Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ)"""
        name_lower = name.lower()
        return [c for c in self.characters 
                if name_lower in c.get('name', '').lower()]


def create_character_template() -> Dict[str, Any]:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù„Ø¨ ÙØ§Ø±Øº Ù„Ø´Ø®ØµÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©"""
    return {
        "character_id": "",
        "novel_id": "",
        "name": "",
        "age": None,
        "gender": "",
        "nationality": "",
        "occupation": "",
        "role": "",
        "traits": [],
        "core_values": [],
        "arc": "",
        "quote": "",
        "fsa_usage": 0.0,
        "colloquial_usage": 0.0
    }


def merge_datasets(file_paths: List[str], output_path: str):
    """
    Ø¯Ù…Ø¬ Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª JSONL ÙÙŠ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
    
    Args:
        file_paths: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±Ø§Ø¯ Ø¯Ù…Ø¬Ù‡Ø§
        output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø§ØªØ¬
    """
    all_characters = []
    
    for file_path in file_paths:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    all_characters.append(json.loads(line))
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for char in all_characters:
            f.write(json.dumps(char, ensure_ascii=False) + '\n')
    
    print(f"âœ“ ØªÙ… Ø¯Ù…Ø¬ {len(all_characters)} Ø´Ø®ØµÙŠØ© ÙÙŠ {output_path}")


# Ù…Ø«Ø§Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    print("="*60)
    print("Ø£Ø¯ÙˆØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø¯Ø§ØªØ§ Ø³ÙŠØª Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("="*60)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§ØªØ§ Ø³ÙŠØª Ø¬Ø¯ÙŠØ¯
    dataset = ArabicCharacterDataset()
    
    # Ø¥Ø¶Ø§ÙØ© Ø´Ø®ØµÙŠØ§Øª Ù…Ø«Ø§Ù„
    characters_examples = [
        {
            "character_id": "char_001",
            "novel_id": "novel_001",
            "name": "Ø£Ø­Ù…Ø¯ Ø§Ù„Ø®Ø·ÙŠØ¨",
            "age": 32,
            "gender": "Ø°ÙƒØ±",
            "role": "Ø¨Ø·Ù„",
            "traits": ["Ø´Ø¬Ø§Ø¹", "Ù…ØªØ±Ø¯Ø¯", "Ø¹Ø§Ø·ÙÙŠ"],
            "occupation": "Ù…Ø¯Ø±Ø³",
            "fsa_usage": 0.65,
            "colloquial_usage": 0.30
        },
        {
            "character_id": "char_002",
            "novel_id": "novel_001",
            "name": "Ù„ÙŠÙ„Ù‰ Ø§Ù„Ù…Ù†ØµÙˆØ±ÙŠ",
            "age": 28,
            "gender": "Ø£Ù†Ø«Ù‰",
            "role": "Ø­Ø¨ÙŠØ¨Ø©",
            "traits": ["Ø°ÙƒÙŠØ©", "Ù…Ø³ØªÙ‚Ù„Ø©", "Ø´Ø¬Ø§Ø¹Ø©"],
            "occupation": "ØµØ­ÙÙŠØ©",
            "fsa_usage": 0.70,
            "colloquial_usage": 0.25
        }
    ]
    
    for char in characters_examples:
        dataset.add_character(char)
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    dataset.print_statistics()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    errors = dataset.validate()
    
    # Ø­ÙØ¸ Ø¥Ù„Ù‰ Ù…Ù„Ù
    dataset.save_to_jsonl('output_characters.jsonl')
    
    # ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ CSV
    dataset.export_to_csv('output_characters.csv')
    
    print("\nâœ… Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
